{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6947d542",
   "metadata": {},
   "source": [
    "# Predict mushroom edibleness\n",
    "\n",
    "Build a Machine learning model that predicts whether a mushroom is **poisonous** or **edible**.\n",
    "1. Import modules\n",
    "2. Explore data\n",
    "3. Clean data if necessary (NaN values etc.)\n",
    "4. Split data into train and test sets\n",
    "5. Choose and train ML model\n",
    "6. Check model accuracy, precision, recall and f1 scores\n",
    "7. Perform Hyperparameter tuning if necessary, compare scores\n",
    "8. Build ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c043d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy Score:  0.9895384615384616\n",
      "Model Precision Score:  0.9987357774968394\n",
      "Model Recall Score:  0.9801488833746899\n",
      "Model F1 Score:  0.9893550407013149\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 2. Initial data exploration\n",
    "df = pd.read_csv('mushrooms.csv')\n",
    "#print(df.info())\n",
    "#print(df.head())\n",
    "\n",
    "# 3. Encode categorical data into numerical for use with ML models\n",
    "for i in df.columns:\n",
    "    df[i] = df[i].astype('category')\n",
    "    df[i] = df[i].cat.codes\n",
    "#print(df.info())\n",
    "#print(df.head())\n",
    "    \n",
    "# 4.1 Split data into X, y\n",
    "y = df['class']\n",
    "X = df.drop('class', axis=1)\n",
    "\n",
    "# 4.2 Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# 5. Based on data types and number of samples the SVC model is chosen (default value for hyperparameter 'C' is 1)\n",
    "clf = SVC(C=1) \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 6. Check model accuracy, precision, recall and f1 scores\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Model Accuracy Score: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Model Precision Score: \", precision_score(y_test, y_pred))\n",
    "print(\"Model Recall Score: \", recall_score(y_test, y_pred))\n",
    "print(\"Model F1 Score: \", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40dc3440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 'C':  SVC(C=10)\n",
      "[{'C': 1}, {'C': 2}, {'C': 3}, {'C': 4}, {'C': 5}, {'C': 6}, {'C': 7}, {'C': 8}, {'C': 9}, {'C': 10}, {'C': 11}, {'C': 12}, {'C': 13}, {'C': 14}, {'C': 15}, {'C': 16}, {'C': 17}, {'C': 18}, {'C': 19}, {'C': 20}, {'C': 21}, {'C': 22}, {'C': 23}, {'C': 24}, {'C': 25}, {'C': 26}, {'C': 27}, {'C': 28}, {'C': 29}, {'C': 30}, {'C': 31}, {'C': 32}, {'C': 33}, {'C': 34}, {'C': 35}, {'C': 36}, {'C': 37}, {'C': 38}, {'C': 39}, {'C': 40}, {'C': 41}, {'C': 42}, {'C': 43}, {'C': 44}, {'C': 45}, {'C': 46}, {'C': 47}, {'C': 48}, {'C': 49}]\n",
      "[0.98738319 0.99430722 0.99769219 0.99846142 0.9990768  0.9993845\n",
      " 0.99969219 0.99984604 0.99984604 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.        ]\n",
      "     C  Accuracy\n",
      "0    1  0.987383\n",
      "1    2  0.994307\n",
      "2    3  0.997692\n",
      "3    4  0.998461\n",
      "4    5  0.999077\n",
      "5    6  0.999384\n",
      "6    7  0.999692\n",
      "7    8  0.999846\n",
      "8    9  0.999846\n",
      "9   10  1.000000\n",
      "10  11  1.000000\n",
      "11  12  1.000000\n",
      "12  13  1.000000\n",
      "13  14  1.000000\n",
      "14  15  1.000000\n",
      "15  16  1.000000\n",
      "16  17  1.000000\n",
      "17  18  1.000000\n",
      "18  19  1.000000\n",
      "19  20  1.000000\n",
      "20  21  1.000000\n",
      "21  22  1.000000\n",
      "22  23  1.000000\n",
      "23  24  1.000000\n",
      "24  25  1.000000\n",
      "25  26  1.000000\n",
      "26  27  1.000000\n",
      "27  28  1.000000\n",
      "28  29  1.000000\n",
      "29  30  1.000000\n",
      "30  31  1.000000\n",
      "31  32  1.000000\n",
      "32  33  1.000000\n",
      "33  34  1.000000\n",
      "34  35  1.000000\n",
      "35  36  1.000000\n",
      "36  37  1.000000\n",
      "37  38  1.000000\n",
      "38  39  1.000000\n",
      "39  40  1.000000\n",
      "40  41  1.000000\n",
      "41  42  1.000000\n",
      "42  43  1.000000\n",
      "43  44  1.000000\n",
      "44  45  1.000000\n",
      "45  46  1.000000\n",
      "46  47  1.000000\n",
      "47  48  1.000000\n",
      "48  49  1.000000\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 7. Hyperparameter tuning - find best value for 'C'\n",
    "#print(clf.get_params().keys())\n",
    "\n",
    "parameters = {'C': [x for x in range(1, 50)]}\n",
    "\n",
    "# 7.1 Create and fit a GridSearchCV model\n",
    "gs = GridSearchCV(clf, parameters)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "# 7.2 Show which hyperparameter performed best\n",
    "print(\"Best 'C': \", gs.best_estimator_)\n",
    "\n",
    "# 7.3 Print the parameters and mean test score\n",
    "print(gs.cv_results_['params'])\n",
    "print(gs.cv_results_['mean_test_score'])\n",
    "\n",
    "# 7.4 Create and print Pandas DataFrame\n",
    "cv_table = pd.concat([pd.DataFrame(gs.cv_results_['params']), pd.DataFrame(gs.cv_results_['mean_test_score'], columns=['Accuracy'])], axis=1)\n",
    "print(cv_table)\n",
    "\n",
    "# Calculate and print accuracy, precision, recall, and f1 scores of the model on best 'C'\n",
    "acc = gs.score(X_test, y_test)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7dbffbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy Score:  1.0\n",
      "Model Precision Score:  1.0\n",
      "Model Recall Score:  1.0\n",
      "Model F1 Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "# 7.5 Fit a new SVC model based on best 'C' (Note: This value is slightly different on each fit of the first model)\n",
    "clf2 = SVC(C=10) \n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "# 7.6 Check model accuracy, precision, recall and f1 scores\n",
    "y_pred = clf2.predict(X_test)\n",
    "\n",
    "print(\"Model Accuracy Score: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Model Precision Score: \", precision_score(y_test, y_pred))\n",
    "print(\"Model Recall Score: \", recall_score(y_test, y_pred))\n",
    "print(\"Model F1 Score: \", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c726d76f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
